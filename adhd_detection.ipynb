{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "271b1d6e",
   "metadata": {},
   "source": [
    "# ADHD Dectection\n",
    "[INTRODUCTION OF THE PROBLEM HERE]\n",
    "\n",
    "## Dataset:\n",
    "[ADD AND COMMENT ABOUT DATASETS HERE]\n",
    "\n",
    "## Task:\n",
    "[ADD TASK HERE]\n",
    "\n",
    "## Integrants:\n",
    "Name, Matricola, Email\n",
    "\n",
    "- Jan Elfes, 2040496, jan.elfes@studenti.unipd.it\n",
    "\n",
    "- Santiago Víquez Segura, 2048722, santiago.viquezsegura@studenti.unipd.it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e0d929",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f1949d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from config_local import helpers\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "hp = helpers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1b08b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/jan/TOSHIBA EXT/SMHDD_22/data/\n"
     ]
    }
   ],
   "source": [
    "_data_path = hp.get_data_path()\n",
    "print(_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721160bf",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f1aee",
   "metadata": {},
   "source": [
    "Before working with the FMRI data we will fit a logistic regression classifier on the phenotypic tabular data to come up with a baseline. We expect that any experiment using the FMRI data outperforms the following result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "908e3bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ScanDir ID</th>\n",
       "      <th>Site</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Handedness</th>\n",
       "      <th>DX</th>\n",
       "      <th>Secondary Dx</th>\n",
       "      <th>ADHD Measure</th>\n",
       "      <th>ADHD Index</th>\n",
       "      <th>Inattentive</th>\n",
       "      <th>...</th>\n",
       "      <th>Full4 IQ</th>\n",
       "      <th>Med Status</th>\n",
       "      <th>QC_Rest_1</th>\n",
       "      <th>QC_Rest_2</th>\n",
       "      <th>QC_Rest_3</th>\n",
       "      <th>QC_Rest_4</th>\n",
       "      <th>QC_Anatomical_1</th>\n",
       "      <th>QC_Anatomical_2</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000804</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.29</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1023964</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.29</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>123</td>\n",
       "      <td>-999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1057962</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1099481</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.04</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1127915</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.44</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ScanDir ID  Site  Gender    Age  Handedness  DX Secondary Dx   \\\n",
       "0     1000804     5     1.0   7.29        0.83   0           NaN   \n",
       "1     1023964     5     1.0   8.29        0.57   3           NaN   \n",
       "2     1057962     5     1.0   8.78     -999.00   1           NaN   \n",
       "3     1099481     5     0.0   8.04        0.50   1           NaN   \n",
       "4     1127915     5     0.0  12.44        0.21   0           NaN   \n",
       "\n",
       "   ADHD Measure  ADHD Index  Inattentive  ...  Full4 IQ  Med Status  \\\n",
       "0             2          40           41  ...       109           1   \n",
       "1             2          60           56  ...       123        -999   \n",
       "2             2          77           81  ...       129           1   \n",
       "3             2          86           82  ...       116           1   \n",
       "4             2          42           43  ...       124           1   \n",
       "\n",
       "   QC_Rest_1  QC_Rest_2  QC_Rest_3  QC_Rest_4  QC_Anatomical_1  \\\n",
       "0        1.0        0.0        NaN        NaN              1.0   \n",
       "1        1.0        0.0        NaN        NaN              1.0   \n",
       "2        1.0        NaN        NaN        NaN              1.0   \n",
       "3        1.0        0.0        NaN        NaN              1.0   \n",
       "4        1.0        1.0        NaN        NaN              1.0   \n",
       "\n",
       "   QC_Anatomical_2  Fold  Partition  \n",
       "0              NaN   4.0      train  \n",
       "1              1.0   3.0      train  \n",
       "2              0.0   1.0      train  \n",
       "3              1.0   2.0      train  \n",
       "4              1.0   4.0      train  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phenotypic_df = pd.read_csv(_data_path + \"NYU_phenotypic.csv\")\n",
    "phenotypic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f6d608",
   "metadata": {},
   "source": [
    "We are going to use `\"Gender\", \"ADHD Index\", \"Age\", \"Handedness\", \"Inattentive\", \"Hyper/Impulsive\", \"Verbal IQ\",\"Performance IQ\", \"Full4 IQ\", \"Med Status\", \"QC_Rest_1\", \"QC_Rest_2\", \"QC_Anatomical_1\", \"QC_Anatomical_2\"` as predictors and use the token `-999` to fill and recognize NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d48de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Gender\", \"ADHD Index\", \"Age\", \"Handedness\", \n",
    "            \"Inattentive\", \"Hyper/Impulsive\", \"Verbal IQ\",\n",
    "           \"Performance IQ\", \"Full4 IQ\", \"Med Status\",\n",
    "            \"QC_Rest_1\", \"QC_Rest_2\", \"QC_Anatomical_1\", \n",
    "            \"QC_Anatomical_2\"]\n",
    "\n",
    "phenotypic_df = phenotypic_df[features + [\"DX\", \"Fold\", \"Partition\"]].fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411a4a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 -- f1-Score (val): 0.544041184041184\n",
      "Fold 2 -- f1-Score (val): 0.8856209150326796\n",
      "Fold 3 -- f1-Score (val): 0.7632043808514397\n",
      "Fold 4 -- f1-Score (val): 0.7854291037682042\n",
      "Fold 5 -- f1-Score (val): 0.691800356506239\n",
      "\n",
      "Average f1-Score (val): 0.7340191880399494\n"
     ]
    }
   ],
   "source": [
    "train_df = phenotypic_df[phenotypic_df[\"Partition\"] == \"train\"]\n",
    "test_df = phenotypic_df[phenotypic_df[\"Partition\"] == \"test\"]\n",
    "scores = []\n",
    "\n",
    "for fold in range(1, 6):\n",
    "    X_train = train_df[train_df[\"Fold\"] != fold][features]\n",
    "    y_train = train_df[train_df[\"Fold\"] != fold][\"DX\"]\n",
    "    \n",
    "    X_val = train_df[train_df[\"Fold\"] == fold][features]\n",
    "    y_val = train_df[train_df[\"Fold\"] == fold][\"DX\"]\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=7000,\n",
    "                         solver=\"saga\",\n",
    "                         penalty=None,\n",
    "                         random_state=42).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_val)\n",
    "    \n",
    "    score = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "    scores.append(score)\n",
    "    print(f\"Fold {fold} -- f1-Score (val): {score}\")\n",
    "print(f\"\\nAverage f1-Score (val): {np.mean(scores)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7a6f419",
   "metadata": {},
   "source": [
    "# Lasso\n",
    "\n",
    "As first model we will use a simple Lasso regression for the fMRI data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e05e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypic_df = pd.read_csv(_data_path + \"NYU_phenotypic.csv\").fillna(-999)\n",
    "dic = {}\n",
    "\n",
    "for i, row in phenotypic_df.iterrows():\n",
    "    \n",
    "    id = str(row['ScanDir ID']).zfill(7)\n",
    "    fold = int(row['Fold'])\n",
    "    part = row['Partition']\n",
    "\n",
    "    if fold != -999:\n",
    "        file = _data_path + f\"{part}/fold{fold}/wmean_mrda{id}_session_1_rest_1.nii.gz\"\n",
    "        img = nib.load(file)\n",
    "        data = img.get_fdata()\n",
    "        y = row['DX']\n",
    "        y_bin = int(y>=1)\n",
    "        dic[id] = {\"img\":img, \"data\":data, \"dx\":y, \"dx_bin\":y_bin, \"part\":part, \"fold\":fold}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43fccaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loader(dic, i):\n",
    "    X_val = []\n",
    "    X_train = []\n",
    "    y_val = []\n",
    "    y_train = []\n",
    "\n",
    "    for id, subj in dic.items():\n",
    "\n",
    "        if ((subj[\"part\"]==\"train\") & (subj[\"fold\"]==i)):\n",
    "            X_val.append(subj['data'].reshape(-1))\n",
    "            y_val.append(subj['dx_bin'])\n",
    "        \n",
    "        if ((subj[\"part\"]==\"train\") & (subj[\"fold\"]!=i)):\n",
    "            X_train.append(subj['data'].reshape(-1))\n",
    "            y_train.append(subj['dx_bin'])\n",
    "    \n",
    "    return np.array(X_train), np.array(y_train), np.array(X_val), np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c32758c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 133574) (136,) (35, 133574) (35,)\n",
      "(137, 133574) (137,) (34, 133574) (34,)\n",
      "(137, 133574) (137,) (34, 133574) (34,)\n",
      "(137, 133574) (137,) (34, 133574) (34,)\n",
      "(137, 133574) (137,) (34, 133574) (34,)\n"
     ]
    }
   ],
   "source": [
    "# Create X and y array\n",
    "for i in range(1, 6):\n",
    "    X_train, y_train, X_val, y_val = train_loader(dic, i)\n",
    "    print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e19dec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 -- f1-Score (val): 0.5413632119514472\n",
      "Fold 2 -- f1-Score (val): 0.6470588235294118\n",
      "Fold 3 -- f1-Score (val): 0.6470588235294118\n",
      "Fold 4 -- f1-Score (val): 0.6803884780929257\n",
      "Fold 5 -- f1-Score (val): 0.5013077593722755\n",
      "\n",
      "Average f1-Score (val): 0.6034354192950944\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for fold in range(1, 6):\n",
    "\n",
    "    X_train, y_train, X_val, y_val = train_loader(dic, fold)\n",
    "\n",
    "    clf = Lasso(alpha=0.01,\n",
    "                random_state=42,\n",
    "                max_iter=7000).fit(X_train, y_train)\n",
    "    y_pred = np.round(clf.predict(X_val))\n",
    "    \n",
    "    score = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "    scores.append(score)\n",
    "    print(f\"Fold {fold} -- f1-Score (val): {score}\")\n",
    "print(f\"\\nAverage f1-Score (val): {np.mean(scores)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "453120ca",
   "metadata": {},
   "source": [
    "## Model selection Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25715d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c937b1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Lambda = 0.001 \tAverage f1-Score (val): 0.5212004801920768\n",
      " \t\tMean Squared Error: \t0.5714285714285714\n",
      "\n",
      " Lambda = 0.003593813663804626 \tAverage f1-Score (val): 0.531281846071762\n",
      " \t\tMean Squared Error: \t0.5142857142857142\n",
      "\n",
      " Lambda = 0.01291549665014884 \tAverage f1-Score (val): 0.5346423013649905\n",
      " \t\tMean Squared Error: \t0.4952380952380952\n",
      "\n",
      " Lambda = 0.046415888336127795 \tAverage f1-Score (val): 0.5363225290116046\n",
      " \t\tMean Squared Error: \t0.48571428571428565\n",
      "\n",
      " Lambda = 0.1668100537200059 \tAverage f1-Score (val): 0.5319151660664265\n",
      " \t\tMean Squared Error: \t0.48571428571428565\n",
      "\n",
      " Lambda = 0.5994842503189409 \tAverage f1-Score (val): 0.5363958916900093\n",
      " \t\tMean Squared Error: \t0.4628571428571429\n",
      "\n",
      " Lambda = 2.1544346900318843 \tAverage f1-Score (val): 0.5421253762050726\n",
      " \t\tMean Squared Error: \t0.45714285714285713\n",
      "\n",
      " Lambda = 7.742636826811277 \tAverage f1-Score (val): 0.5102548502168995\n",
      " \t\tMean Squared Error: \t0.45714285714285713\n",
      "\n",
      " Lambda = 27.825594022071257 \tAverage f1-Score (val): 0.4783843242287265\n",
      " \t\tMean Squared Error: \t0.45714285714285713\n",
      "\n",
      " Lambda = 100.0 \tAverage f1-Score (val): 0.45192929777370006\n",
      " \t\tMean Squared Error: \t0.4514285714285714\n"
     ]
    }
   ],
   "source": [
    "cv_lambda = np.logspace(-3, 2, 30)\n",
    "coefs = []\n",
    "f1_scores = []\n",
    "f1_scores_mean = []\n",
    "mse_scores = []\n",
    "mse_scores_mean = []\n",
    "\n",
    "for lam in cv_lambda:\n",
    "    for fold in range(1, 6):\n",
    "\n",
    "        X_train, y_train, X_val, y_val = train_loader(dic, fold)\n",
    "\n",
    "        clf = Lasso(alpha=lam,\n",
    "                    random_state=42,\n",
    "                    max_iter=7000).fit(X_train, y_train)\n",
    "        y_pred = np.round(clf.predict(X_val))\n",
    "        \n",
    "        score = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "        f1_scores.append(score)\n",
    "        mse_scores.append(mse)\n",
    "        coefs.append(clf.coef_)\n",
    "\n",
    "    f1_scores_mean.append(np.mean(f1_scores[-5:]))\n",
    "    mse_scores_mean.append(np.mean(mse_scores[-5:]))\n",
    "\n",
    "    print(f\"\\n Lambda = {np.round(lam, 4)}  \\tAverage f1-Score (val): {f1_scores_mean[-1]}\\n \\t\\t\\tMean Squared Error: \\t{mse_scores_mean[-1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b783d63",
   "metadata": {},
   "source": [
    "TODO: need to implement AIC/BIC for model selection. For Lasso in sklearn this seems to be `LassoLarsIC` but did not make it work yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c465012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LassoLarsIC\n",
    "\n",
    "# clf = LassoLarsIC(criterion=\"aic\")\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cdfd716",
   "metadata": {},
   "source": [
    "# Multiclass Lasso\n",
    "\n",
    "Takes 1 hour to run all 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2b7e246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 -- f1-Score (val): 0.5966666666666668\n",
      "Fold 2 -- f1-Score (val): 0.7058823529411765\n",
      "Fold 3 -- f1-Score (val): 0.4668730650154798\n",
      "Fold 4 -- f1-Score (val): 0.5892014776925263\n",
      "Fold 5 -- f1-Score (val): 0.47058823529411764\n",
      "\n",
      "Average f1-Score (val): 0.5658423595219935\n"
     ]
    }
   ],
   "source": [
    "# scores = []\n",
    "\n",
    "# for fold in range(1, 6):\n",
    "\n",
    "#     X_train, y_train, X_val, y_val = train_loader(dic, fold)\n",
    "\n",
    "#     clf = LogisticRegression(max_iter=7000,\n",
    "#                              solver=\"saga\",\n",
    "#                              penalty=\"l1\",\n",
    "#                              C=1/0.1,\n",
    "#                              random_state=42).fit(X_train, y_train)\n",
    "#     y_pred = clf.predict(X_val)\n",
    "    \n",
    "#     score = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "#     scores.append(score)\n",
    "#     print(f\"Fold {fold} -- f1-Score (val): {score}\")\n",
    "# print(f\"\\nAverage f1-Score (val): {np.mean(scores)}\")                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a4817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "24aed787140b6ca219884ec1f80be3ab203fadf185eda90b949a24475a265daf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
